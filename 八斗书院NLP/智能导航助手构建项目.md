# 项目背景

智能对话系统（如聊天机器人、智能语音助手）、搜索引擎和垂直领域问答系统的核心。

不是闲聊助手，理解查询意图，并将其转化为计算机可以精确处理和执行的结构化数据。

## 输入和输出

原始输入（text）: “查询许昌到中山的汽车。”

语义解析输出（Structured Data）:

```

intent： 意图 （用户提问的类型）
QUERY（查询）、BOOK（预订）、CANCEL（取消）、COMPARE（对比）
domain： 领域
slots：槽位（实体）
{ “Dest”: “中山”, “Src”: “许昌” }
```

结构化查询

```

SELECT * FROM bus_schedule WHERE src = '许昌' AND dest = '中山';
```

组织为自然语言 -》 输出

## 项目产出（一个可部署、可调用、高准确率的XX领域助手）

智能对话助手（智能体）接收用户的自然语言输入，并输出结构化的、机器可读的数据，以便后续系统执行精确的查询。

## 项目技术路线

- BERT（微调）：意图识别 + 实体识别
- GPT（提示词、后序可以考虑微调）：大模型识别意图 + 实体

## 项目时间轴

1M


# 技术方案

## 业务逻辑

![2025-09-27_10-03.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/f88f016d-2215-4b43-a90f-9a28878703cc.jpeg)


## 实施方案


你的实施方案框架合理，但可以进一步**细化、优化优先级、明确技术选型与风险控制**。以下是结合你项目目标（高准确率、可部署、垂直领域对话助手）的**增强版实施方案**，包含时间分配、技术路线对比、交付物和风险提示：

---

## ✅ 增强版实施方案（总周期：3~4 周）

### 阶段 1：数据构建与验证（7天）✅ **关键！决定上限**


| 任务                | 详细说明                                                                                                                   | 交付物                                               | 风险控制         |
| ------------------- | -------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------- | ---------------- |
| **1.1 定义 Schema** | 明确 4 意图 + 8 槽位（含多值`VehicleType`），<br />制定 BIO 标签体系                                                       | `schema.json`（含 intent/slot 定义）                 | 避免后期槽位变更 |
| **1.2 数据采集**    | - 真实用户日志（如有）<br>- 模板生成<br />（“查{Src}到{Dest}的{Vehicle}”）<br>- <br />人工编写（覆盖口语、错别字、省略） | 原始语料库<br />（≥3000 条）                        | 覆盖长尾表达     |
| **1.3 标注与质检**  | - 使用 Label Studio 标注<br>- 按字切分 + <br />BIO 标注<br>- 双人校验（Kappa ≥ 0.8）                                      | 标注数据集<br />（JSONL 格式）                       | 避免标注噪声     |
| **1.4 数据划分**    | Train: 70%, Dev: 15%, <br />Test: 15%（按意图分层抽样）                                                                    | `train.jsonl`, <br />`dev.jsonl`, <br />`test.jsonl` | 确保各意图均衡   |

> 📌 **建议**：优先保证 **BOOK / QUERY** 数据质量（高频意图），COMPARE / CANCEL 可稍少。

---

### 阶段 2：模型选型与训练（10~12天）✅ **核心：验证哪种方案性价比最高**

#### 技术路线对比（按优先级排序）


| 方案                                                            | 优点                                                                     | 缺点                                                    | 适用场景                         | 推荐指数   |
| --------------------------------------------------------------- | ------------------------------------------------------------------------ | ------------------------------------------------------- | -------------------------------- | ---------- |
| **A. 统一 BERT（多任务）**<br>（你已实现）                      | - 共享语义，准确率高<br>- 单模型，<br />部署简单<br>- 训练快（1~2 小时） | 需标注数据                                              | **首选！** 数据 ≥1000 条        | ⭐⭐⭐⭐⭐ |
| **B. 双 BERT（独立模型）**                                      | 意图/槽位解耦，调试灵活                                                  | 模型大、延迟高、数据利用率低                            | 不推荐（除非意图差异极大）       | ⭐⭐       |
| **C. 大模型 Prompt（Zero/Few-shot）**<br>（如 ChatGLM3 / Qwen） | 无需训练，快速验证                                                       | - 成本高（API/推理）<br>- 输出不稳定<br>- 难结构化      | 仅用于**基线对比**               | ⭐⭐       |
| **D. 大模型微调（LoRA）**<br>（如 ChatGLM3-6B + LoRA）          | 强泛化，支持复杂表达                                                     | - 显存要求高（≥24G）<br>- 训练慢（天级）<br>- 部署复杂 | 数据极少（<500）或需支持多轮对话 | ⭐⭐⭐     |

#### ✅ 推荐执行顺序：

1. **先跑通方案 A（统一 BERT）** → 快速得到 baseline（第 3 天出结果）
2. **用方案 C（大模型 Prompt）做对比实验** → 验证数据质量上限
3. **若 A 效果达标（Intent Acc > 92%, Slot F1 > 88%），则放弃 C/D**
4. **仅当 A 效果差且数据极少时，考虑 D（大模型微调）**

#### 训练计划（以方案 A 为主）：


| 天数     | 任务                                              |
| -------- | ------------------------------------------------- |
| 第1天    | 搭建统一 BERT 多任务代码（使用你修正后的模型）    |
| 第2天    | 数据预处理（tokenizer 对齐、padding、label 映射） |
| 第3天    | 训练 + 在 dev 集调参（lr=2e-5, epoch=5）          |
| 第4天    | 测试集评估（Intent Acc, Slot F1, 联合准确率）     |
| 第5天    | 错误分析（bad case 归因：数据？模型？）           |
| 第6-7天  | 迭代：补充数据 or 调整模型（如加 CRF 层）         |
| 第8-10天 | 尝试大模型 Prompt 基线（可选）                    |

> 📊 **评估指标必须包含**：
>
> - 意图准确率（Intent Accuracy）
> - 槽位 F1-score（按实体类型）
> - **端到端准确率**（Intent 正确 **且** 所有槽位正确）

---

### 阶段 3：业务系统构建（7~10天）✅ **让模型真正可用**


| 模块               | 关键任务                                                                                                                              | 技术栈建议                           |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------ |
| **3.1 后处理引擎** | - BIO → 实体合并<br>- 多值槽位聚合（VehicleType）<br>- 实体归一化（“高铁”→“train”）<br>- 日期标准化（“明天”→“2025-09-28”） | Python +`cn2an` + `chinese-calendar` |
| **3.2 查询生成器** | 根据 intent + slots 生成：<br>- SQL 模板<br>- 或结构化 Query 对象（推荐）                                                             | Jinja2 模板 / 策略模式               |
| **3.3 API 服务**   | 提供 HTTP 接口：<br>`POST /parse {text} → {intent, slots, query}`                                                                    | FastAPI + Uvicorn                    |
| **3.4 部署**       | - Docker 容器化<br>- 模型量化（可选）<br>- 压测（QPS ≥ 50）                                                                          | Docker + Nginx + Prometheus          |
| **3.5 监控与日志** | 记录输入/输出、延迟、错误率                                                                                                           | ELK / 自定义日志                     |

#### 示例 API 响应：

```json
{
  "intent": "BOOK",
  "slots": {
    "Src": "许昌",
    "Dest": "中山",
    "Date": "2025-09-28",
    "PassengerCount": 1
  },
  "query": {
    "action": "create_booking",
    "params": { ... }
  }
}
```

---

## 🚦 风险与应对策略


| 风险                             | 应对措施                                                                      |
| -------------------------------- | ----------------------------------------------------------------------------- |
| **数据不足导致效果差**           | - 启动模板生成 + 回译增强<br>- 用大模型生成伪标签（需人工校验）               |
| **多值槽位识别不准**             | - 在后处理中加入规则兜底（如“和”“或”分割）<br>- 单独评估 `VehicleType` F1 |
| **线上延迟高**                   | - 模型导出为 ONNX<br>- 使用 CPU 优化（Intel OpenVINO）                        |
| **意图混淆（QUERY vs COMPARE）** | - 在训练数据中增加对比样本<br>- 联合准确率作为核心指标                        |

---

## 📅 最终交付物清单


| 类别     | 交付物                                                           |
| -------- | ---------------------------------------------------------------- |
| **数据** | 标注数据集（含 train/dev/test）、schema 定义                     |
| **模型** | 训练好的统一 BERT 模型（.bin + config）、评估报告                |
| **代码** | - 模型训练脚本<br>- 后处理模块<br>- FastAPI 服务<br>- Dockerfile |
| **文档** | - API 接口文档<br>- 部署手册<br>- 错误码说明                     |

---

## ✅ 总结：你的方案如何优化？


| 你的原计划                              | 建议增强点                                                            |
| --------------------------------------- | --------------------------------------------------------------------- |
| “构建数据集，7天”                     | → 细化为**采集→标注→质检→划分** 四步，<br />强调 schema 先行      |
| “模型训练：双BERT/统一BERT/大模型...” | →**明确优先级**：统一 BERT 为主，<br />大模型仅作基线                |
| “业务构建”                            | → 拆解为**后处理→查询生成→API→部署** 四模块，<br />强调结构化输出 |

> 💡 **核心原则**：
> **小步快跑，数据驱动，先跑通再优化**。
> 用 **统一 BERT 多任务模型** 作为主线，7 天内出第一个可测版本，再迭代。

如果需要，我可以为你提供：

- 完整的 **数据标注模板（Label Studio 配置）**
- **统一 BERT 训练脚本（含评估）**
- **FastAPI 服务代码框架**

欢迎继续沟通！
