# 提示词工程

### 1. **Zero-shot Prompting（零样本提示）**

- **定义**：模型在没有见过任何任务示例的情况下，仅通过自然语言指令完成任务。
- **示例**：
  *“将以下英文翻译成中文：Hello, how are you?”*
- **特点**：依赖模型的泛化能力，适用于通用任务。

---

### 2. **Few-shot Prompting（少样本提示）**

- **定义**：在提示中提供少量（通常3–5个）输入-输出示例，引导模型学习任务模式。
- **示例**：
  *“翻译示例：
  英文：Good morning → 中文：早上好
  英文：Thank you → 中文：谢谢
  现在翻译：How are you? →”*
- **特点**：比零样本更可靠，尤其对复杂或模糊任务。

---

### 3. **Chain-of-Thought (CoT) Prompting（思维链提示）**

- **定义**：引导模型在输出最终答案前，先生成中间推理步骤（“让我们一步步思考”）。
- **示例**：
  *“小明有5个苹果，吃了2个，又买了3个。他现在有几个苹果？
  → 首先，5 - 2 = 3；然后，3 + 3 = 6。所以答案是6。”*
- **特点**：显著提升复杂推理（如数学、逻辑）性能。

---

### 4. **Meta Prompting（元提示）**

- **定义**：使用一个“元提示”来指导模型如何生成或优化其他提示。
- **应用**：自动构建高质量提示模板，或让模型扮演“提示工程师”角色。
- **示例**：
  *“你是一个提示工程师。请为‘总结新闻文章’任务设计一个有效的提示。”*

---

### 5. **Self-Consistency（自一致性）**

- **定义**：结合CoT，通过多次采样不同推理路径，选择最一致的答案（多数投票）。
- **目的**：减少CoT中单次推理的随机性错误。
- **流程**：生成多个CoT → 提取答案 → 投票选最高频答案。

---

### 6. **Generate Knowledge Prompting（知识生成提示）**

- **定义**：先让模型生成与问题相关的背景知识，再基于该知识回答问题。
- **示例**：
  *“问题：为什么天空是蓝色的？
  → 先生成：‘瑞利散射导致短波长蓝光比红光更容易散射……’
  → 再回答：‘因为……’”*
- **优势**：提升模型在知识密集型任务中的准确性。

---

### 7. **Prompt Chaining（提示链）**

- **定义**：将复杂任务拆解为多个子任务，用多个提示依次调用模型，前一输出作为后一输入。
- **示例**：
  *步骤1：提取文章关键点 → 步骤2：根据关键点写摘要 → 步骤3：润色摘要*
- **适用**：多阶段任务（如分析→总结→建议）。

---

### 8. **Tree of Thoughts (ToT)（思维树）**

- **定义**：扩展CoT，允许模型在推理过程中探索多个可能的中间状态（像树一样分支），并通过搜索（如BFS/DFS）找到最优路径。
- **对比**：CoT是线性推理，ToT是树状探索。
- **适用**：需要规划、回溯的问题（如谜题、代码生成）。

---

### 9. **Retrieval-Augmented Generation (RAG)（检索增强生成）**

- **定义**：在生成前，从外部知识库（如维基百科）检索相关信息，将检索结果作为上下文输入模型。
- **优势**：解决模型知识过时或幻觉问题，提升事实准确性。
- **典型架构**：检索器 + 生成器（如DPR + LLM）。

---

### 10. **Automatic Reasoning and Tool-use（自动推理与工具调用）**

- **定义**：模型在推理过程中调用外部工具（计算器、API、数据库等）获取精确信息或执行操作。
- **示例**：
  *“计算2023年1月1日是星期几？” → 调用日历API*
- **代表框架**：ReAct（见下文）。

---

### 11. **Automatic Prompt Engineer（自动提示工程）**

- **定义**：使用算法（如梯度搜索、强化学习、LLM自身）自动优化提示词，以最大化任务性能。
- **方法**：
  - 基于反馈迭代优化提示
  - 让LLM生成并评估多个候选提示

---

### 12. **Active-Prompt**

- **定义**：动态选择或生成对当前任务最有效的示例或指令，通常基于不确定性或任务难度。
- **思想**：不是固定few-shot示例，而是“按需”激活最相关示例。

---

### 13. **Directional Stimulus Prompting（定向刺激提示）**

- **定义**：通过特定关键词或结构“刺激”模型关注某些方向（如情感、逻辑、风格）。
- **示例**：
  *“以批判性视角分析以下政策……”*
  *“用乐观的语气重写这段话……”*
- **目的**：控制输出风格或焦点。

---

### 14. **Program-Aided Language Models (PAL)（程序辅助语言模型）**

- **定义**：让模型生成可执行代码（如Python）来解决推理问题，再运行代码获得答案。
- **优势**：将符号推理外包给编程语言，避免LLM数值/逻辑错误。
- **示例**：数学题 → 生成Python代码 → 执行 → 返回结果。

---

### 15. **ReAct（Reasoning + Acting）**

- **定义**：结合推理（Reason）与行动（Act），模型交替生成思考步骤和调用工具（如搜索、API）。
- **流程**：
  *Thought: 我需要知道巴黎人口 → Action: Search[Paris population] → Observation: 216万 → Thought: … → Answer*
- **目标**：实现交互式、工具增强的推理。

---

### 16. **Reflexion（反思）**

- **定义**：模型在完成任务后进行自我评估，若失败则生成反思并重试。
- **机制**：
  1. 尝试解决问题
  2. 自我检查错误
  3. 基于反思调整策略并重新尝试
- **应用**：强化学习、智能体决策。

---

### 17. **Multimodal CoT（多模态思维链）**

- **定义**：将CoT扩展到多模态输入（如图像+文本），在推理中融合视觉与语言信息。
- **示例**：
  *看图回答：“图中有几个红色方块？” → 先描述图像内容 → 再计数推理*
- **模型**：需支持多模态（如LLaVA, Flamingo）。

---

### 18. **Graph Prompting（图提示）**

- **定义**：将问题或知识表示为图结构（节点=概念，边=关系），利用图神经网络或结构化提示引导推理。
- **应用**：知识图谱问答、复杂关系推理。
- **方式**：
  - 将图结构编码为文本提示
  - 或让模型在图上进行消息传递式推理

---

### 总结关系图（简化）：

```
基础提示 → Zero-shot / Few-shot
           ↓
增强推理 → CoT → Self-Consistency / ToT / Multimodal CoT
           ↓
外部增强 → RAG（知识） / Tool-use（工具） → ReAct / PAL
           ↓
自动化   → Auto Prompt Engineer / Meta Prompting / Active-Prompt
           ↓
高级框架 → Reflexion（反思） / Graph Prompting（结构化）
```

这些技术常组合使用（如：Few-shot + CoT + Self-Consistency + RAG），以应对复杂现实任务。
