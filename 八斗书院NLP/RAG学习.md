# RAG学习

![202503091504324.png](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/888afbd3-b1ef-4f4f-a2ec-eff3f28e385d.png)

## RAG定义

在自然语言处理领域，大型语言模型(LLM)如GPT-3、BERT等已经取得了显著的进展，它们能够生成连贯、自然的文本，回答问题，并执行其他复杂的语言任务。然而，这些模型存在一些固有的局限性，如“模型幻觉问题”、“时效性问题”和“数据安全问题”。为了克服这些限制，检索增强生成(RAG)技术应运而生。

![2025-09-16_08-15.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/01ee858c-5483-44ac-b119-8673cc24b5fb.jpeg)

RAG技术结合了大型语言模型的强大生成能力和检索系统的精确性。它允许模型在生成文本时，从外部知识库中检索相关信息，从而提高生成内容的准确性、相关性和时效性。这种方法不仅增强了模型的回答能力，还减少了生成错误信息的风险。

## RAG常见流程

![政企问答项目RAG流程](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/6caead23-9836-469a-b35b-9f0f42f05802.jpeg)

![个人知识库RAG流程](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/f4cdcab4-499a-465b-8a73-a064d3f94d4a.jpeg)

从上述流程中我们可以看到RAG中常见功能部分有文件解析功能、切片划分功能、向量嵌入功能、查询改写功能、路由功能、数据库、多路召回功能、排序功能、大模型回答功能。

## RAG中功能模块

### 文件解析功能

现实生活中我们常见的文件格式有文本(txt)，word文档，pdf文档，md文档。文本解析就是将文档中的内容（文字，图片，表格等信息）提取出来。这里比较困难的是pdf文档解析。

为了解析文件我们可以使用如下技术：

* pdfplumber：pdf文件文本提取和图片提取
* 深度学习的方法：ocr等技术，paddle-ocr，pdf2md
* 多模态大模型的方法：qwen-vl等

![2025-09-16_08-41.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/347f5f4b-67fd-47ed-8c83-a92cba387a00.jpeg)

### 切片划分功能

参考文章：https://zhuanlan.zhihu.com/p/1912878600853623201

RAG技术中划分chunk是为了更好地适应大模型的处理能力，提高检索和生成的效率和准确性，以及优化内容的相关性。

**从大模型输入角度模型**

> 在预训练过程中通常有上下文长度限制，如果输入的文本超过这个长度，超出部分会被丢弃，从而影响模型的性能表现。因此，需要将长文档分割成小块，以适应模型的上下文窗口。

**从语义表示的差异性角度**

> 长文档中各个片段的语义可能存在较大差异，如果将整个文档作为一个整体进行知识检索，会导致语义杂揉，影响检索效果。将长文档切分成多个小块，可以使得每个小块内部表意一致，块之间表意存在多样性，从而更充分地发挥知识检索的作用。

**划分Chunk的注意事项**

在进行chunk划分时，需要保留每个chunk的原始内容来源信息，这包括但不限于：

> 页面编号：记录每个chuk来自文档的哪一页，有助于在需要时快速定位原始信息。
> 文档标识：为每个文档分配一个唯一的标识符，以便在检索时能够准确引用。
> 版本控制：如果文档会更新，记录cunk对应的文档版本，确保内容的一致性和准确性。

随着时间的推移，原始文档可能会更新或修改（可能使用新的文档处理方法重新划分chuk)。因此，在划分chunk时需要考虑：

> 更新策略：制定一个清晰的策略，以确定何时以及如何更新chunk,以保持信息的最新性。
> 版本兼容性：确保新l旧版本的chunk能够兼容，或者能够明确区分不同版本的chunk。

此外chunk之间的顺序可能对理解整个文档至关重要：

> 顺序标记：为每个chuk分配顺序编号或时间戳，以保持它们的逻辑顺序。
> 顺序检索：在检索时，确保能够按照正确的顺序检索和展示chunk。

![v2-72acb98d3c9ec6806011f9ca3b802e17_b.webp](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/c7c2610c-fc5c-41d9-94b0-b7dc2d60a4a4.webp)

**常用切片划分的策略如下**：

1. 固定大小：设置100个字符为一个chunk
2. 滑动窗口：在固定大小的情况下加入overlap
3. 按照文档结构：先划分为段落，再划分为句子
4. 递归分块：先划分章节、再划分段落、句子
5. 语义分块：将含义相近的句子划分到一个chunk
6. 大模型分块：写一个提示词，让大模型分块；
7. Late chunking:提取token特征，对chunk tokensi进行pooling;

#### 固定大小切分

将文档按照预设的字符数、词数或句子数进行等间隔划分。例如每段包含500个字符或5个句子。该方法实现简单，但容易打断语义边界，可能导致上下文缺失或内容重复。

![v2-4defad599bbfd1773c082c815aa1c2df_1440w.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/7461faf6-59e8-4cf6-b263-85c791a2b265.jpeg)

#### 文档结构分块

利用原始文档的结构信息（如HTML标签、Markdown标题、PDF书签、Word段落等）进行切分。比如以章节、小标题、列表项为边界进行分块。

![v2-bc06c016ad0f247e5757bbe1c133356d_b.webp](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/74cc9fba-c350-4b30-9641-4c8294737190.webp)

这种方式在处理格式规范的文档（如手册、报告）时效果尤为突出。

![v2-01afd8700d9a93b5c56a878b4f484247_1440w.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/85224810-5181-400d-b5c2-f3497ab03bae.jpeg)

#### 层次递归分块

![2025-09-16_08-50.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/79b08918-afc9-4e22-a7ed-13f45e3aeadd.jpeg)

在保持固定长度的同时，尝试以语义结构（如段落、句子、标点）为边界递归地切分文本。若段落太长无法容纳于块中，则再递归切分为句子，直到满足长度要求。

![v2-080935082e37fdabb9fee9db9279fba5_b.webp](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/0d84a105-9815-4f58-8cf5-a5c4dce10fcd.webp)

![v2-d7ba9e86e42de2764170cce7ce518e62_1440w.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/72eae67c-873b-4eaf-a02d-628311001069.jpeg)

#### 语义分块

通过自然语言处理技术（如句向量相似度、话题建模等）判断文本语义的边界，在语义上自然断句。

![2025-09-16_09-00.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/ca3254e6-8192-46a4-8e5a-7369372b3444.jpeg)

![v2-e0f65749b7f6a139182a0c6209b5ead7_b.webp](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/1498a369-3ba9-47e6-a0b9-52841036cd9b.webp)

以向量相似度为例，将句子或段落转换为向量，通过计算相邻句段的余弦相似度，如果判断两个段落语义上属于同一单元，那么就进行合并。

![v2-0c546f112ac1bb72b9ad5a7bf6f0f292_1440w.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/89969f67-e858-4a2d-b2af-5685471d3dde.jpeg)

这种方式能提升分块的语义连贯性，适用于逻辑紧密的文章，但计算代价较高，依赖模型质量。

#### 大模型分块

构建提示词，借助大模型输入文本长的特点对长文本进行切分。这里类似是先对长文本进行滑动窗口切块，然后借助大模型进行分块。

![v2-de87a53022dbabb18b7598cae91f0c78_b.webp](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/324665ef-e2a1-43b5-9365-9e1dfcbed970.webp)

借助大语言模型来“理解”文档内容并主动划定分块边界。例如，提示模型判断哪些段落构成完整的语义单元，或根据任务需求生成最佳的分块方案。这种方式智能程度高，但计算成本也相对较大，适合高精度应用场景。

#### Late chunking

![2025-09-16_08-56.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/d3420337-732c-40aa-a4cd-2b0f6ab0b564.jpeg)

#### 评价Chunk划分方法

**分块归因(Chunk Attribution)**

> 分块归因用于评估每个检索到的分块是否对模型的响应产生了影响。它使用一个二元指标，将每个分块归类为“有影响”（(Attributed)或“无影响”(Not Attributed)。分块归因与分块利用率(Chunk Utilization)密切相关，其中归因确定分块是否对响应产生了影响，而利用率衡量分块文本在影响中所占的程度。只有被归为“有影响”的分块才能有大于零的利用率得分。

**分块利用率(Chunk Utilization)**

> 分块利用率衡量每个检索到的分块中有多少文本对模型的响应产生了影响。这个指标的范围是 0到1，其中1表示整个分块影响了响应，而较低的值，如0.5，则表示存在“无关”文本，这部分文本并未对响应产生影响。分块利用率与分块归因紧密相关，归因确定分块是否影响了响应，而利用率衡量分块文本在影响中所占的部分。只有被归为“有影响”的分块才能有大于零的利用率得分。

#### 分块可视化工具

https://chunkviz.up.railway.app/

### 向量嵌入功能

参考文章：https://zhuanlan.zhihu.com/p/1912910452339484544

**Embedding（嵌入向量）** 是将文字、图片、语音等“人类语言”**转换为**“计算机语言”的关键一步。它的作用，是把一句话或者一个词，变成一串可以进行数学运算的数字向量，让模型能“理解”我们在说什么。

![v2-240153b1807c7f36748478856aec8365_1440w.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/97aad5ad-8142-45c9-8553-648d9f0ce662.jpeg)

#### 选择嵌入模型

在 RAG 系统中，嵌入模型（Embedding Model）就像是用户与知识库之间的翻译官——它决定了“你在说什么”和“它能不能听懂”。

选择一个合适的嵌入模型，能大幅提升检索质量与上下文匹配度。选得好，模型如虎添翼，问啥答啥；选不好，可能“查到不对题，答得更离谱”。

以下是选型时需要重点考虑的几个维度


| 考量维度       | 说明                                                               |
| -------------- | ------------------------------------------------------------------ |
| 语义表现力     | 能否正确捕捉句子的含义？是否支持中文、多 语言？                    |
| 模型大小/效率  | 越大越准？不一定！推理速度、GPU/CPU占 用也是关键                   |
| 训练目标       | 是面向“检索”训练的（如BGE+)，还是面 向“生成”或“通用”训练的？ |
| 向量归一化     | 是否适合FAISS+等向量库索引（部分模型需 显式归一化)                 |
| 开源/闭源      | 是否可部署本地？是否支持商用？                                     |
| 社区支持与文档 | 模型活跃度越高，调试与优化越方便                                   |

#### 主流嵌入模型

以下是一些主流且表现优秀的嵌入模型，涵盖中英双语、轻量级部署、本地化支持等需求。

**中文 & 多语言方向**


| 模型名称       | 简介与特点                                                                                |
| -------------- | ----------------------------------------------------------------------------------------- |
| BGE (BAAI)     | 北京智源开源的检索导向模型，支持中文/英 文，带bge-base-zh,bge-m3等版本，性能与 速度兼顾。 |
| E5 系列+       | 多语言嵌入模型（包括e5-base,e5-large)， 适用于检索任务，广泛支持中英文句子匹配。          |
| GTE系列+       | 百度提出的 GTE 模型（如 gte-base)，表现稳 定、部署友好，适合中文问答和文档检索。          |
| text2vec 系列+ | 来自 HuggingFace 的中文句向量模型，如 shibing624/text2vec-base-multilingual, 易 用性高。  |

**英文或通用方向**


| 模型名称         | 简介与适用场景                                                                |
| ---------------- | ----------------------------------------------------------------------------- |
| MiniLM+ / MPNet+ | HuggingFace SentenceTransformers 库的经典嵌入模型，轻量快速、适合低资源场景。 |
| Instructort      | 支持带任务说明的嵌入（如"Representthe query for retrieval: xx")，效果优秀。   |
| OpenAl Adat      | GPT体系内置嵌入模型（如text- embedding-ada-002)，闭源但商用表现稳定 强劲。    |
| Cohere Embed+    | 专注于“可控语义检索”的服务型模型，API 提供简单，商用接口友好。              |

如果不知道选哪个，建议：

* 小模型部署快，适合原型验证（如 `bge-small-zh`）
* 大模型更准，适合上线产品（如 `bge-large-zh-v1.5`）
* 想本地部署？就用 BGE、E5、GTE
* 要省心云服务？那就试试 OpenAI Ada、Cohere

### 查询增强功能

![2025-09-16_10-37.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/c5d7ca37-5ce7-4dae-bb81-112fbbbcc17f.jpeg)

#### Query预处理方法

1. 引导进行二次提问、引导到已知的提问；
2. Query Rewriting(查询重写)：将用户的提问改写一下，转换多个提问；
3. Step-Back Strategy(后退一步策略)：让大模型生成一个更加抽象、更加基础的问题
4. Hypothetical Document Embeddings(HyDE)
5. 拒绝回答、特定格式回答；

#### 二次提问

Multi-Query Rewriting策略的核心思想是通过从不同角度生成多个查询来提高检索召回率。这种方法特别适合于以下场景：

> 用户查询不清晰或含糊；

> 需要从多个角度理解用户意图；

> 单一查询无法覆盖完整信息；

从用户的原始查询中生成多个不同的查询变体，以覆盖更广泛的信息和视角。这可以通过使用语言模型(LLM)来实现，模型会根据原始查询生成多个相关但不同的查询。

#### 查询重写

Query Rewriting(查询重写)策路涉及将单个查询改写为多个查询，以便对检索器执行这些查询。这是高级检索技术中的关键步骤。通过查询重写，可以为[ensemble retrieval]和[fusion]生成多个查询，从而提高检索结果的质量。

![2025-09-16_10-39.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/20d42cd2-1689-40bd-aad5-6cabdc2579fb.jpeg)

#### 后退一步策略

Step-Back Strategy(后退一步策略)是一种通过从更抽象或更基础的层面重新审视问题的方法。

这种策略可以：

> 扩大检索范围；

> 获取更完整的上下文信息；

> 提供更全面的答案

首先，让LLM根据原始问题提出一个更高层次的后退问题，并检索这个后退问题的相关信息。基于高层次概念或原则的事实，LLM可以推理出原始问题的解决方案。

#### HYDE

HyDE不是直接根据原始查询搜索相关文档，而是首先构建一个可能回答查询的假设性文档。虽然这个假设性文档在细节上可能不是完全准确的，但它作为一个相关文档的有价值示例，捕捉到了相关性的本质。

检索过程利用对比训练中编码的文档-文档相似性，通过内积识别与假设答案紧密对齐的文档。最相以的真实文档被检索出来，并作为查询的潜在响应呈现，提高了检索的准确性。

![3d8104a5eb91e4bf7970e608dfbbbe55.png](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/e9afc90d-cf4a-4d1e-a515-20dc5b48b09d.png)

#### 拒绝回答

这里可以使用文本分类模型或者大模型提示词的方式来进行实现。

### 路由功能

参考文章：https://blog.csdn.net/m0_59164520/article/details/139511351

参考文章：https://zhuanlan.zhihu.com/p/707377668

参考文章：https://developer.baidu.com/article/detail.html?id=3373273

#### 路由定义

在RAG应用中，用户查询可能涉及多个数据源，如向量数据库、关系型数据库、第三方系统等。这些数据源存储着不同类型和格式的数据，因此需要根据用户查询的意图和上下文，智能地选择最相关的数据源进行检索。路由正是实现这一智能选择的关键机制。

通过路由，RAG应用能够：

提高检索效率：根据用户查询快速定位到最相关的数据源，减少不必要的检索时间。
优化用户体验：确保用户获得准确、有用的回答，提升用户满意度。
增强应用灵活性：支持多种数据源和查询类型，满足不同场景下的需求。



#### 路由的类型

在RAG应用中，路由主要分为逻辑路由和语义路由两种类型。

逻辑路由：

逻辑路由主要依赖于LLM（大型语言模型）对查询进行推理，并根据推理结果选择更合适的数据存储。它通常使用分类的方式，将查询归类到特定的数据源或处理流程中。逻辑路由的实现相对简单，但要求LLM具备较高的推理能力和准确性。

语义路由：

语义路由则更注重查询与数据源之间的语义相似性。它将查询和一组prompt向量化表示，并基于相似性选择合适的prompt或数据源。语义路由的实现更为复杂，但能够更准确地捕捉查询与数据源之间的关联，适用于对语义理解要求较高的场景。

#### 路由的实现方式

在RAG应用中，路由的实现方式多种多样，以下是一些常见的实现方法：

**使用LLM进行函数调用：**

通过LLM的函数调用能力，可以实现基于查询结果的动态路由。例如，定义一个包含多个数据源的函数，并根据LLM对查询的推理结果选择相应的数据源进行调用。

**基于嵌入和相似性搜索：**

利用嵌入技术将查询和数据源表示为向量，并通过相似性搜索找到最匹配的数据源。这种方法适用于大规模数据集的快速检索。

**自定义路由逻辑：**

根据具体应用场景的需求，可以自定义路由逻辑。例如，根据查询的关键词、类别或上下文信息，选择相应的数据源或处理流程。

---

由于数据源的多样性，信息的存储方式以及我们希望与之交互的方式也可能是多种多样的。有些数据可能存储在向量存储中，有些存储在 SQL 数据库中，有些我们可能需要通过 API 调用访问，因为它位于第三方系统中。

![基于查询意图的 RAG 系统路由到不同的数据源](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/02df8fa2-0869-4224-9d0d-74ece59ff429.jpeg)



对于相同的数据，也可以设置不同的向量存储，并针对不同的查询类型进行优化。例如，可以设置一个向量存储来回答摘要类型问题，另一个用于回答特定的定向类型问题。

根据问题的不同，我们可能还想将查询路由到不同的组件类型。例如，我们可能想把查询传递给代理、矢量存储，或者直接传递给 LLM 进行处理，所有这些都是根据问题的性质来决定的。
![根据用户的查询路由到不同的组件类型](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/5389e895-8fcc-4859-a404-12339d1ee556.jpeg)

我们甚至可以根据所提问题定制提示模板。

![根据用户查询通过不同的提示模板进行路由](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/f56f6788-5ad4-4d0c-ac8a-40a23f4db940.jpeg)



总之，我们有很多理由想要改变和引导用户在应用程序中的查询流。我们的应用程序要满足的用例越多，我们就越有可能在整个应用程序中提出路由要求。

路由器本质上只是我们可以用来指导查询控制流的 If/Else 语句。

但有趣的是，它们需要根据自然语言输入做出决定。因此，我们正在寻找一种基于自然语言描述的离散输出。

由于很多路由逻辑都是基于使用 LLM 或机器学习算法（本质上是非确定性的），因此我们无法保证路由器总是 100% 做出正确的选择。此外，我们也不可能预测进入路由器的所有不同查询变化。不过，利用最佳实践和一些测试，我们应该能够使用路由器来帮助创建更强大的 RAG 应用程序。


#### 六种不同的路由器

1. **LLM补全路由器（LLM Completion Routers）**：
   LLM补全路由器使用LLM（大型语言模型）的完成调用功能，从用户查询中提取关键信息，并根据这些信息选择最合适的处理路径。这种路由器要求LLM从提供的单词选项列表中返回最能描述查询的单个单词，然后使用该单词作为If/Else条件的一部分来控制应用程序流程。
2. **LLM函数调用路由器（LLM Function Calling Routers）**：
   LLM函数调用路由器利用LLM的函数调用能力来选择要遍历的路线。不同的路线被设置为具有适当描述的函数，在LLM函数调用中，根据传递给LLM的查询，它能够返回正确的函数（即路线）供我们使用。这种路由器在LlamaIndex中的Pydantic Router中得到了广泛应用。
3. **语义路由器（Semantic Routers）**：
   语义路由器利用嵌入和相似性搜索来选择最佳的路由。每条路由都有一组与之关联的示例查询，这些查询被嵌入并存储为向量。传入的查询也会被嵌入，并与其他示例查询进行相似性搜索，从而选择最匹配的路由。这种路由器能够处理更复杂的查询意图，提高路由的准确性。
4. **零样本分类路由器（Zero Shot Classification Routers）**：
   零样本分类路由器利用零样本分类模型为文本分配一个标签，该标签是路由器预先定义的标签集中的一个。这种路由器可以在没有额外训练的情况下处理新的查询意图，提高了路由器的灵活性和适应性。
5. **语言分类路由器（Language Classification Routers）**：
   语言分类路由器能够识别查询语言的语言种类，并根据语言种类对查询进行路由。这对于需要多语言解析能力的应用程序非常有用。通过识别查询的语言，路由器可以将查询引导到相应的处理组件或数据源。
6. **逻辑路由器（Logical Routers）**：
   逻辑路由器基于离散逻辑工作，例如针对字符串长度、文件名、整数值等的条件。它们不是基于理解自然语言查询的意图，而是基于现有的、离散的变量来做出选择。这种路由器在处理简单的查询意图时非常高效。

### 数据库

#### 关系型数据库

关系型数据库(SQL)依据”一对一、一对多、多对多”的关系模型创建数据库，并将数据以二维表格的形式储存，各个表之间建立关系，通过这些关联的表格间分类、合并、连接或选取等运算来实现数据的管理。

#### 非关系型数据库

非关系型数据库(NoSQL)按存储方式分为向量数据库、图形数据库、文档存储数据库、宽列数据库、键值存储数据库等，能够实现非结构化或半结构化数据的处理和存储。


| 数据库类型     | 数据模型          | 主要特点                         | 代表性产品    |
| -------------- | ----------------- | -------------------------------- | ------------- |
| 文档存储数据库 | JSON/XML文档      | 灵活的文档结构，适合复杂数据     | ElasticSearch |
| 列存储数据库   | 列族              | 高效存储稀疏数据，适合大规模数据 | Cassandra     |
| 图数据库       | 图结构 (节点和边) | 适合复杂关系数据的存储和查询     | Neo4j         |
| 时间序列数据库 | 时间序列数据      | 高效存储和查询时间序列数据       | InfluxDB      |
| 向量数据库     | 高维向量          | 高效的相似性搜索，适合嵌入向量   | FAISS/Milvus  |


#### 向量数据库

向量数据库是一种专门用于存储和查询向量数据的数据库系统。向量数据库支持对向量数据进行各种操作

**向量检索**：根据给定的向量，找出数据库中与之最相似的向量，例如在图像向量数据库中，用户输入一张图片进行搜索时，先将这张图片转换为一个向量，通过向量之间的近似检索，找到与输入图片最相似的图片。

**向量聚类**：根据给定的相以度度量，将数据库中的向量分类，例如根据图片的内容或风格，将图片分成不同的主题。

**向量降维**：根据给定的目标维度，将数据库中的高维向量转换成低维向量，以便于可视化或压缩存储：

**向量计算**：根据给定的算法或模型，对数据库中的向量进行计算或分析，例如根据神经网络模型，对图片进行分类或标注。

![2025-09-16_15-06.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/e08ed57c-da5b-4982-8680-5f8db4b7908b.jpeg)

#### 各种数据库在RAG中应用对比

**关系型数据库与非关系型数据库的对比**


| 特性           | 传统关系型数据库                 | 向量数据库                 |
| -------------- | -------------------------------- | -------------------------- |
| 数据类型       | 数值、字符串、时间等传统数据类型 | 向量数据，不存储原始数据   |
| 数据规模       | 大，按照库、表和行               | 中等                       |
| 数据组织方式   | 基于表格，按照行和列组织         | 基于向量，按照向量维度组织 |
| 查找方式       | 精确查找：点查/范围查            | 近似查找                   |
| 低时延，高并发 | 是                               | 中等                       |
| 下游应用场景   | 元信息存储                       | 非结构化数据检索           |

**关系型数据库与非关系型数据库各自在RAG项目中的应用**


| 类型                   | 在RAG中的角色                            | 记忆口诀                             |
| ---------------------- | ---------------------------------------- | ------------------------------------ |
| 关系型数据库 (RDBMS)   | “守门人” <br />管权限、管状态、管合规  | “谁看得见？是不是最新？有没有效？“ |
| 非关系型数据库 (NoSQL) | “内容仓库" <br />存原文、存结构、存弹性 | “给啥内容？怎么存？变不变？         |
| 向量数据库             | “搜题高手" <br />理解语义、快速匹配     | “意思对不对？离得多近？             |


#### 向量检索方法

各种向量数据库提供不同的相似性计算方法，但对于文本，最常用的两种度量是：

> 余弦距离产生一个规范化的值（介于-1和1之间）
> 欧氏距离是计算两个向量之间的直线距离

两种不同的检索方式，它们针对不同的需求和应用场景：

> 精确检索(Exact Retrieval)：精确地找到与查询完全匹配的文档或数据项。
> 近似检索(Approximate Retrieval):返回与查询相以数据项，通过权衡精度和效率来提高搜索速度。


#### 向量近似检索方法

##### LSH

局部敏感哈希(Locality Sensitive Hashing)是一种使用近似最近邻搜索的索引技术，它的特点是快速，同时仍然提供一个近似、非穷举的结果。

LSH使用一组哈希函数将相似向量映射到“桶”中，从而使相似向量具有相同的哈希值。这样，就可以通过比较哈希值来判断向量之间的相以度。

![2025-09-16_15-39.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/0ebe2e5d-6245-4a38-a20b-097e5773ba7a.jpeg)

##### KD Tree

Kd-Tree(K-dimensional tree)是一棵二叉树，树中存储的是一些K维数据。在一个K维数据集合上构建一棵Kd-Tree代表了对该K维数据集合构成的K维空间的一个划分，即树中的每个结点就对应了一个K维的超矩形区域。 

1,递制归构建左右子树：对切分元素左边的数据和右边的数据分别递归构建KD树的左子树和右子树。

 2定位查询点的叶子节点：从根节点开始，根据查询点的各维坐标值，递归地沿着树分支向下寻找，直到到达叶子节点。

![2025-09-16_15-41.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/4fb6056c-a2d4-4e75-9576-f27848772737.jpeg)


##### K-Means

保存向量数据后，先对向量数据先进行K-Means聚类，划定了N个聚类中心，然后将每个向量分配到最近的聚类中心，经过聚类算法不断调整聚类中心位置，就可以将向量数据分成M个簇。每次搜索时，只需要先判断搜索向量属于哪个簇，然后再在这一个簇中进行搜索。

关键点：如何确定聚类个数？

![2025-09-16_15-42.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/1f49024f-5a37-46f6-a3f3-072394175e94.jpeg)


##### Product Quantization(PQ)

Product Quantization(PQ)是一种用于降低高维向量存储和搜索复杂度的技术。它通过将高维向量划分为多个低维子向量，然后在每个子向量上进行独立的聚类，以减少码本的大小，从而降低内存占用和提高搜索速度。 

1.向量分解：将原始高维向量分解为多个低维子向量。 

2独立聚类：对每个子向量进独立的聚类，生成子码本。 

3.编码：将原始向量的每个子向量编码为对应的子码本中的索引。

在搜索时，将每个子向量的编码值组合成原始向量的近似编码，通过在子码本中查我得到近以的最近邻。

![2025-09-16_15-43.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/83a3a60c-7759-4203-beea-7c8dbac3bf84.jpeg)

![2025-09-16_15-44.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/47904c47-51b4-4513-886e-1e9535a3e14f.jpeg)

##### Hierarchical Navigable Small Worlds(HNSW)

Hierarchical Navigable Small Worlds(HNSW)是一种用于近似最近邻搜索的算法，它通过构建多层的图结构来提高搜索效率。HNSW算法具有较高的搜索质量和速度，特别适用于大规模高维向量数据集。 

1图结构：将向量空间划分为多个层级，每个层级构建一个小世界图(Small World Graph)。 

2节点连接：在每个小世界图中，每个节点与其最近邻的一些节点相连接，形成一个局部连通的结构。 

3多层结构：高层的图结构具有更大的边缘长度，适用于快速搜索，而低层的图结构具有较小的边缘长度，适用于准确搜索。 

4搜索过程：在搜索时，从最高层的图开始，通过快速搜索逐渐降低到低层的图，以保证搜索的效率和准确性。

![2025-09-16_15-45.jpg](https://cdn.jsdelivr.net/gh/zilong-ding/note-gen-image-sync@main/5eba7dae-3f62-484c-ac45-b0a40f547dcd.jpeg)




### 多路召回功能

参考文章：https://blog.csdn.net/pumpkin84514/article/details/145150498






### 重排序






### 大模型功能
