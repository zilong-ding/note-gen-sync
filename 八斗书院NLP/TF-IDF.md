# TF-IDF算法介绍及实现

## TF-IDF算法介绍


TF-IDF（term frequency–inverse document frequency，词频-逆向文件频率）是一种用于**信息检索**（information retrieval）与**文本挖掘**（text mining）的常用加权技术。

TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。**字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降**。

TF-IDF的主要思想是：**如果某个单词在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类**。

### TF是词频（Term Frequency）

词频（TF）表示词条（关键字）在文本中出现的频率

这个数字通常会被归一化(一般是词频除以文章总词数), 以防止它偏向长的文件。

公式：

$$
tf_{ij}=\frac{n_{i,j}}{\sum_kn_{k,j}}
$$


即：

$$
TF_w=\frac{\text{在某一类中词条}w\text{出现的次数}}{\text{该类中所有的词条数目 }}
$$


其中 **ni,j** 是该词在文件 **dj** 中出现的次数，分母则是文件 dj 中所有词汇出现的次数总和；

### **IDF是逆向文件频率(Inverse Document Frequency)**

逆向文件频率 (IDF) ：某一特定词语的IDF，可以由总文件数目除以包含该词语的文件的数目，再将得到的商取对数得到。

如果包含词条t的文档越少, IDF越大，则说明词条具有很好的类别区分能力

公式：

$$
idf_i=\log\frac{|D|}{|\{j:t_i\in d_j\}|}
$$
